---
title: "m10"
author: "Will Tirone"
format: pdf
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| include: FALSE
library(MatchIt)
library(tidyverse)
library(kableExtra)
data = read.csv('lalondeMeth10 (1).csv')
```

# Q1)

Looking at the summary output below, the columns `age`, `nodegree`,
`married`, `re74`, and `re75` appear the most unbalanced. Really, the
only balanced characteristic is `educ`.

```{r}
m = matchit(treat ~ age + educ + married + 
              nodegree + re74 + re75,
            data = data,
            method = NULL,
            distance = "glm") 

summary(m)
```

# Q2)

Looking at the initial fit of the model, we see evidence of
heteroskedasticity and maybe slight deviance from normality in the QQ
plot. The deviance from normality is probably less of a concern, but the
errors fan out pretty significantly and have structure.

However, we can't use log transforms on most of the variables since
they're either binary or contain 0 values. However, removing the
variables `re74` and `re75` seem to help in removing structure in the
residuals. I imagine the high number of 0 values for these two income
covariates are hurting the model.

```{r}
m2 = lm(re78 ~ treat + age + educ + married + nodegree,
        data = data)

plot(m2, which=1)
```

Coefficient estimates for covariates (including treatment) are below:

```{r}
coef(summary(m2))
```

And the confidence intervals are here, for the treatment effect as well
as other covariates.

```{r}
confint(m2)
```

# Q3)

## a)

Printing the `matches` object, we see that it is a 1:1 NN match without
replacement, with the propensity scores estimated with logistic
regression using all the covariates / background characteristics.

Since I'm not using all the covariates, I'm only including the ones used
in the final model from Q2.

```{r}
matches = matchit(treat ~ age + educ + married + 
              nodegree,
            data = data,
            method = "nearest",
            distance = "glm") 

matches
```

## b)

Here I summarize by including the "matched" and "unmatched" background
covariate summaries. The difference is enormous! Matching makes a huge
difference and we can see the background characteristics are
significantly more balanced after matching.

```{r}
bind_rows(
  data.frame(summary(matches)$sum.matched)[,1:3] |> 
    mutate(type = "matched"),
  data.frame(summary(matches)$sum.all)[,1:3] |> 
    mutate(type = "unmatched"),
) |> kable()

```

## c)

Here using the data from part b) and the formula from the slides, we get
a confidence interval of \[-1276.74, 1680\]. Since this covers 0, we're
not confident that the treatment has any effect.

```{r}
matched_data = match.data(matches)

treat_sum = matched_data |> 
  filter(treat == 1) |>
  group_by() |> 
  summarize(mean = mean(re78),
            std = var(re78)/n())

control_sum = matched_data |> 
  filter(treat == 0) |>
  group_by() |> 
  summarize(mean = mean(re78),
            std = var(re78)/n())

treat_SE = treat_sum |> pull(std)
contr_SE = control_sum |> pull(std)

y_bar_t = treat_sum |> pull(mean)
y_bar_c = control_sum |> pull(mean)

tau_hat = y_bar_t - y_bar_c

val = 1.96 * sqrt(treat_SE + contr_SE)

cat("Point estimate for treatment effect: ", tau_hat, "\n")
cat("95% Conf. Int for treatment effect: ", "[", tau_hat - val, 
    ",", tau_hat + val, "]")

```

# Q4)

Fitting the model again, this time it looks like `re74` and `re75` don't
hurt the distribution of the errors nearly as much. However, we have a
slightly worse looking normality plot. I've tried a handful of
transforms and excluding different variables, but it doesn't seem like
there's much we can do to improve this, it's probably just structure in
the data.

```{r}
m4 = lm(re78 ~ treat + age + educ + married + nodegree + re74 + re75,
        data = matched_data)

plot(m4, which = c(1,2))
```

Coefficient estimates for covariates (including treatment) are below:

```{r}
coef(summary(m4))
```

And the confidence intervals are here, for the treatment effect as well
as other covariates.

```{r}
confint(m4)
```
